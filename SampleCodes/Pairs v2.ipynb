{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Researching a Pairs Trading Strategy\n",
    "\n",
    "Adapted from a Quantopian notebook by Delaney Granizo-Mackenzie\n",
    "\n",
    "Updated for Python 3 and modern Pandas by Ken Gleason\n",
    "\n",
    "Part of the Quantopian Lecture Series:\n",
    "\n",
    "* [www.quantopian.com/lectures](https://www.quantopian.com/lectures)\n",
    "* [github.com/quantopian/research_public](https://github.com/quantopian/research_public)\n",
    "\n",
    "Notebook released under the Creative Commons Attribution 4.0 License.\n",
    "\n",
    "---\n",
    "\n",
    "Pairs trading is a nice example of a strategy based on mathematical analysis. The principle is as follows. Let's say you have a pair of securities X and Y that have some underlying economic link. An example might be two companies that manufacture the same product, or two companies in one supply chain. We'll start by constructing an artificial example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import coint\n",
    "# just set the seed for the random number generator\n",
    "np.random.seed(107)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams[ 'figure.figsize' ] = ( 14, 8 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the Concept: We start by generating two fake securities.\n",
    "We model X's daily returns by drawing from a normal distribution. Then we perform a cumulative sum to get the value of X on each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_returns = np.random.normal(0, 3, 100) # Generate the daily returns\n",
    "# sum them and shift all the prices up into a reasonable range\n",
    "X = pd.Series(np.cumsum(X_returns), name='X') + 50\n",
    "X.plot(figsize = ( 16, 9 ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate Y. Remember that Y is supposed to have a deep economic link to X, so the price of Y should vary pretty similarly. We model this by taking X, shifting it up and adding some random noise drawn from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_noise = np.random.normal(0, 6, 100)\n",
    "Y = X + 5 + some_noise\n",
    "Y.name = 'Y'\n",
    "pd.concat([X, Y], axis=1).plot(figsize=(16,9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cointegration\n",
    "\n",
    "We've constructed an example of two cointegrated series. Cointegration is a \"different\" form of correlation (very loosely speaking). The spread between two cointegrated timeseries will vary around a mean. The expected value of the spread over time must converge to the mean for pairs trading work work. Another way to think about this is that cointegrated timeseries might not necessarily follow a similar path to a same destination, but they both end up at this destination.\n",
    "\n",
    "We'll plot the spread between the two now so we can see how this looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y-X).plot(figsize=(16,9)) # Plot the spread\n",
    "plt.axhline((Y-X).mean(), color='red', linestyle='--') # Add the mean\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for Cointegration\n",
    "\n",
    "That's an intuitive definition, but how do we test for this statistically? There is a convenient test that lives in `statsmodels.tsa.stattools`. We should see a very low p-value, as we've artifically created two series that are as cointegrated as physically possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the p-value of the cointegration test\n",
    "# will inform us as to whether the spread btwn the 2 timeseries is stationary\n",
    "# around its mean\n",
    "score, pvalue, crit_vals = coint(X,Y)\n",
    "print( pvalue )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation vs. Cointegration\n",
    "\n",
    "Correlation and cointegration, while theoretically similar, are not the same. To demonstrate this, we'll show examples of series that are correlated, but not cointegrated, and vice versa. To start let's check the correlation of the series we just generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's very high, as we would expect. But how would two series that are correlated but not cointegrated look? \n",
    "\n",
    "### Correlation Without Cointegration\n",
    "\n",
    "A simple example is two series that just diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_returns = np.random.normal(1, 1, 100)\n",
    "Y_returns = np.random.normal(2, 1, 100)\n",
    "\n",
    "X_diverging = pd.Series(np.cumsum(X_returns), name='X')\n",
    "Y_diverging = pd.Series(np.cumsum(Y_returns), name='Y')\n",
    "\n",
    "pd.concat([X_diverging, Y_diverging], axis=1).plot(figsize=(16,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Correlation: ' + str(X_diverging.corr(Y_diverging)) )\n",
    "score, pvalue, crit_val = coint(X_diverging,Y_diverging)\n",
    "print( 'Cointegration test p-value: ' + str(pvalue) )\n",
    "print(score)\n",
    "print(crit_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cointegration Without Correlation\n",
    "\n",
    "A simple example of this case is a normally distributed series and a square wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = pd.Series(np.random.normal(0, 1, 1000), name='Y2') + 20\n",
    "Y3 = Y2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y2 = Y2 + 10\n",
    "Y3[0:100] = 30\n",
    "Y3[100:200] = 10\n",
    "Y3[200:300] = 30\n",
    "Y3[300:400] = 10\n",
    "Y3[400:500] = 30\n",
    "Y3[500:600] = 10\n",
    "Y3[600:700] = 30\n",
    "Y3[700:800] = 10\n",
    "Y3[800:900] = 30\n",
    "Y3[900:1000] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2.plot(figsize=(16,9))\n",
    "Y3.plot()\n",
    "plt.ylim([0, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation is nearly zero\n",
    "print( 'Correlation: ' + str(Y2.corr(Y3)) )\n",
    "score, pvalue, _ = coint(Y2,Y3)\n",
    "print( 'Cointegration test p-value: ' + str(pvalue) )\n",
    "print( score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, the correlation is incredibly low, but the p-value shows perfect cointegration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cointegration and Pairs\n",
    "Because the securities drift towards and apart from each other, there will be times when the distance is high and times when the distance is low. The trick of pairs trading comes from maintaining a hedged position across X and Y. If both securities go down, we neither make nor lose money, and likewise if both go up. We make money on the difference of the two reverting to the mean. In order to do this we'll watch for when X and Y are far apart, then short Y and long X. Similarly we'll watch for when they're close together, and long Y and short X.\n",
    "\n",
    "## Finding cointegrated securities\n",
    "The best way to do this is to start with securities you suspect may be cointegrated and perform a statistical test. If you just run statistical tests over all pairs, you'll fall prey to multiple comparison bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a method to look through a list of securities and test for cointegration between all pairs. It returns a cointegration test score matrix, a p-value matrix, and any pairs for which the p-value was less than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cointegrated_pairs(df):\n",
    "    security_names = df.columns\n",
    "    n = len(security_names)\n",
    "    score_matrix = np.zeros((n, n))\n",
    "    pvalue_matrix = np.ones((n, n))\n",
    "    pairs = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            S1 = df[security_names[i]]\n",
    "            S2 = df[security_names[j]]\n",
    "            result = coint(S1, S2)\n",
    "            score = result[0]\n",
    "            pvalue = result[1]\n",
    "            score_matrix[i, j] = score\n",
    "            pvalue_matrix[i, j] = pvalue\n",
    "            if pvalue < 0.05:\n",
    "                pairs.append((security_names[i], security_names[j]))\n",
    "    return score_matrix, pvalue_matrix, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for Cointegrated Pairs in groups of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getstock as gs\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this unless we need to run the data again\n",
    "apikey = \"YOURKEYHERE\"\n",
    "symbol_data = {}\n",
    "#symbol_list = ['MSFT', 'AMZN', 'FB', 'GOOG','NFLX','SPY']\n",
    "symbol_list = ['JPM', 'GS', 'MS', 'ICE', 'USB', 'PNC', 'BK', 'COF', 'INFO', 'BAC']\n",
    "for symbol in symbol_list:\n",
    "    symbol_data[symbol] = gs.getDailyStockPrices(symbol, apikey).adjusted_close\n",
    "    time.sleep(60)\n",
    "\n",
    "securities_df = pd.DataFrame(symbol_data)\n",
    "\n",
    "securities_df = securities_df.loc['2015':'2019']\n",
    "\n",
    "# save the data!\n",
    "securities_df.to_pickle('bankdata.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "securities_df = pd.read_pickle('bankdata.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "securities_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if any pairs are cointegrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap to show the p-values of the cointegration test between each pair of\n",
    "# stocks. Only show the value in the upper-diagonal of the heatmap\n",
    "# (Just showing a '1' for everything in lower diagonal)\n",
    "\n",
    "scores, pvalues, pairs = find_cointegrated_pairs(securities_df)\n",
    "\n",
    "sns.heatmap(pvalues, xticklabels=symbol_list, yticklabels=symbol_list, cmap='RdYlGn_r' \n",
    "                , mask = (pvalues >= 0.95))\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the best pair location?\n",
    "best_pair_loc = np.unravel_index(np.argmin(pvalues, axis=None), pvalues.shape)\n",
    "best_pair_name = symbol_list[best_pair_loc[0]] + \", \" + symbol_list[best_pair_loc[1]]\n",
    "print(str(best_pair_loc) + \": \" + best_pair_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 'COF' and 'BAC' are cointegrated. Let's take a look at the prices to make sure there's nothing weird going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = securities_df['COF']\n",
    "S2 = securities_df['BAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, pvalue, _ = coint(S1, S2)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the spread of the two series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_series = S1 - S2\n",
    "diff_series.plot()\n",
    "plt.axhline(diff_series.mean(), color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The absolute spread isn't very useful in statistical terms. It is more helpful to normalize our signal by treating it as a z-score. This way we associate probabilities to the signals we see. If we see a z-score of 1, we know that approximately 84% of all spread values will be smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(series):\n",
    "    return (series - series.mean()) / np.std(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore(diff_series).plot()\n",
    "plt.axhline(zscore(diff_series).mean(), color='black')\n",
    "plt.axhline(1.0, color='red', linestyle='--')\n",
    "plt.axhline(-1.0, color='green', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Strategy: \n",
    "* Go \"Long\" the spread whenever the z-score is below -1.0\n",
    "* Go \"Short\" the spread when the z-score is above 1.0\n",
    "* Exit positions when the z-score approaches zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we originally defined the \"spread\" as S1-S2:\n",
    "* \"Long\" the spread would mean \"Buy 1 dollar of S1, and Sell Short 1 dollar of S2\" \n",
    "* and vice versa if you were going \"Short\" the spread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just the tip of the iceberg, and only a very simplistic example to illustrate the concepts.  In practice you would want to compute a more optimal weighting for how many shares to hold for S1 and S2.  Some additional resources on pair trading are listed at the end of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average\n",
    "A moving average is just an average over the last $n$ datapoints for each given time. It will be undefined for the first $n$ datapoints in our series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the difference in prices between the 2 stocks\n",
    "difference = S1 - S2\n",
    "difference.name = 'diff'\n",
    "\n",
    "# Get the 10 day moving average of the difference\n",
    "diff_mavg10 = difference.rolling(10).mean()\n",
    "diff_mavg10.name = 'diff 10d mavg'\n",
    "\n",
    "# Get the 60 day moving average\n",
    "diff_mavg60 = difference.rolling(60).mean()\n",
    "diff_mavg60.name = 'diff 60d mavg'\n",
    "\n",
    "_ = pd.concat([diff_mavg60, diff_mavg10, difference], axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the moving averages to compute the z-score of the difference at each given time. This will tell us how extreme the difference is and whether it's a good idea to enter a position at this time. Let's take a look at the z-score now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a rolling 60 day standard deviation\n",
    "std_60 = difference.rolling(60).std()\n",
    "std_60.name = 'std 60d'\n",
    "\n",
    "# Compute the z score for each day\n",
    "zscore_60_10 = (diff_mavg10 - diff_mavg60)/std_60\n",
    "zscore_60_10.name = 'z-score'\n",
    "zscore_60_10.plot()\n",
    "plt.axhline(0, color='black')\n",
    "plt.axhline(1.0, color='red', linestyle='--')\n",
    "plt.axhline(-1.0, color='green', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The z-score doesn't mean much out of context, let's plot it next to the prices to get an idea of what it looks like. We'll take the negative of the z-score because the differences were all negative and that's kinda confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_stocks = securities_df[['COF', 'BAC']]\n",
    "# Plot the prices scaled down along with the negative z-score\n",
    "# just divide the stock prices by 10 to make viewing it on the plot easier\n",
    "pd.concat([two_stocks/10, zscore_60_10], axis=1).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook contained some simple introductory approaches. In practice one should use more sophisticated statistics, some of which are listed here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Augmented-Dickey Fuller test \n",
    "* Hurst exponent\n",
    "* Half-life of mean reversion inferred from an Ornstein–Uhlenbeck process\n",
    "* Kalman filters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
